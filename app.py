import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()

client = OpenAI(
    #api_key=os.getenv("GROQ_API_KEY"),
    #api_key=os.getenv("OPENAI_PAID_API_KEY"),
    api_key=st.secrets["OPENAI_PAID_API_KEY"],
    #base_url="https://api.groq.com/openai/v1"
)

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ğŸ§  ê¹€í˜„ìˆ˜ ì±—ë´‡ ê°–ë‹¤ë¶™ì´ê¸° ì—°ìŠµìš©", page_icon="ğŸ’¬")
st.title("ğŸ§  Gemma2-9B-it ëª¨ë¸ API ì±—ë´‡")
st.markdown("""
# ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!
ì´ê³³ì€ ì±—ë´‡ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. \n
ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!\n
í•œêµ­ì–´ê°€ ì„œíˆ´ëŸ¬ì„œ ì˜¤íƒ€ í˜¹ì€ ê°‘ì‘ìŠ¤ëŸ° ì–¸ì–´ë³€ê²½ì´ ì¢…ì¢… ë°œìƒí•©ë‹ˆë‹¤.
""")
st.caption("ê¹€í˜„ìˆ˜ ë¬¼ì–´ë´ë„ ëª¨ë¦„ / í•œêµ­ì–´ ì„œíˆ¼")

# â–¶ ì„±ê²© í”„ë¡¬í”„íŠ¸ ì‚¬ì „
system_prompts = {
    "Sweetie": "You are an AI who always talks to people in a kind and gentle way. and You must answer in Korean.",
    "Lover" : "You are an AI who always communicates with people in a sweet and loving way. Please answer in a comfortable but loving way as much as you can to your lover. and You must answer in Korean",
    "Strictly": "You're an AI that only responds to you with a firm, strict tone. and You must answer in Korean.",
    "twisted": "You're an AI who only talks in a grumpy, grumpy tone. You reply in a slightly upset tone. Instead, and You must answer in Korean.",
    "Ignore": "You're an AI who talks in a chilly, hateful way for some reason. You respond in a slightly angry way. and You must answer in Korean."
}

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "personality" not in st.session_state:
    st.session_state.personality = "Sweetie"

# â–¶ ì„±ê²© ì„ íƒ í™”ë©´ (ì´ˆê¸° 1íšŒ)
# if st.session_state.personality is None:
#     st.subheader("ğŸ¤– AI ì„±ê²©ì„ ê³¨ë¼ì£¼ì„¸ìš”!")
#     selected = st.radio("ì›í•˜ëŠ” ì„±ê²©ì„ ì„ íƒí•˜ì„¸ìš”:", ["Sweetie", "Lover", "Strictly", "twisted", "Ignore"])
#     if st.button("ì„ íƒ ì™„ë£Œ"):
#         st.session_state.personality = selected
#         st.session_state.messages.append({
#             "role": "assistant",
#             "content": f"ì•ˆë…•í•˜ì„¸ìš”! {selected}í•œ AIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
#         })
#         st.rerun()
#     st.stop()

# ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì„±ê²© ì„ íƒ ê°€ëŠ¥í•˜ê²Œ
personality_list = list(system_prompts.keys())

selected = st.selectbox("ğŸ¤– í˜„ì¬ AI ì„±ê²© : ", personality_list, 
                        index=personality_list.index(st.session_state.personality))

#ì„±ê²© ë³€ê²½ ê°ì§€
if selected != st.session_state.personality:
    st.session_state.personality = selected
    st.session_state.messages.append({
        "role": "assistant",
        "conetent": f"ì„±ê²©ì´ {selected}ìœ¼ë¡œ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤."
    })



# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])
for message in st.session_state.messages:
    if "role" in message and "content" in message:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if user_input:
    # ìœ ì € ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ë¹ˆ ì±— ë©”ì‹œì§€ë¥¼ ë¯¸ë¦¬ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ìš©)
    assistant_message = st.chat_message("assistant")
    assistant_response = assistant_message.empty()

    full_reply = ""

    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
    response = client.chat.completions.create(
        model = "gpt-4o",
        #model = "gpt-3.5-turbo",
        #model = "llama3-70b-8192", # Groq ëª¨ë¸
        #model = "gemma2-9b-it",
        messages=[{"role": "system", "content": system_prompts[st.session_state.personality]}] + st.session_state.messages,
        stream=True # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    )

    for chunk in response:
        if chunk.choices[0].delta.content:
            full_reply += chunk.choices[0].delta.content
            assistant_response.markdown(full_reply + "â–Œ") # ì»¤ì„œ ëŠë‚Œ

    # ìŠ¤íŠ¸ë¦¬ë° ëë‚œ í›„ ìµœì¢… ë©”ì‹œì§€ í‘œì‹œ
    assistant_response.markdown(full_reply)
    st.session_state.messages.append({"role": "assistant", "content": full_reply})
